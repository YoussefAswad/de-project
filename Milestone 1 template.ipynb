{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 1 - EDA and Preprocessing data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load dataset\n",
    "- Explore the dataset and ask atleast 5 questions to give you a better understanding of the data provided to you. \n",
    "- Visualise the answer to these 5 questions.\n",
    "- Cleaing the data\n",
    "- Observe missing data and comment on why you believe it is missing(MCAR,MAR or MNAR) \n",
    "- Observe duplicate data\n",
    "- Observe outliers\n",
    "- After observing outliers,missing data and duplicates, handle any unclean data.\n",
    "- With every change you are making to the data you need to comment on why you used this technique and how has it affected the data(by both showing the change in the data i.e change in number of rows/columns,change in distrubution, etc and commenting on it).\n",
    "- Data transformation and feature engineering\n",
    "- Add a new column named 'Week number' and discretisize the data into weeks according to the dates.Tip: Change the datatype of the date feature to datetime type instead of object.\n",
    "- Encode any categorical feature(s) and comment on why you used this technique and how the data has changed.\n",
    "- Identify feature(s) which need normalisation and show your reasoning.Then choose a technique to normalise the feature(s) and comment on why you chose this technique.\n",
    "- Add atleast two more columns which adds more info to the dataset by evaluating specific feature(s). I.E( Column indicating whether the accident was on a weekend or not). \n",
    "- For any imputation with arbitrary values or encoding done, you have to store what the value imputed or encoded represents in a new csv file. I.e if you impute a missing value with -1 or 100 you must have a csv file illustrating what -1 and 100 means. Or for instance, if you encode cities with 1,2,3,4,etc what each number represents must be shown in the new csv file.\n",
    "- Load the new dataset into a csv file.\n",
    "- **Extremely Important note** - Your code should be as generic as possible and not hard-coded and be able to work with various datasets. Any hard-coded solutions will be severely penalised.\n",
    "- Bonus: Load the dataset as a parquet file instead of a csv file(Parquet file is a compressed file format)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "dataset = 'dataset/1980_Accidents_UK.csv'\n",
    "df_accidents_1980 = pd.read_csv(dataset, index_col=None)\n",
    "df_accidents_1980.head(50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Does accident_index have uniqe values and what is it's relatiion to accident_year and accident_refrence?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is there a relation between accident_severity and number_of_casualties?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"accident_severity\", y=\"number_of_casualties\",\n",
    "            data=df_accidents_1980)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the previous graph there is a direct relationship between accident_severity and number_of_casualties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"accident_severity\", y=\"speed_limit\",\n",
    "            data=df_accidents_1980)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_null = df_accidents_1980.isnull().mean() * 100\n",
    "print(perc_null)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df_accidents_1980.apply(lambda col: col.unique())\n",
    "print(df_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observing Missing and duplicate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### We replace all occurances of 'Data missing or out of range' and -1 with nan to have consistencey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_null = df_accidents_1980.isnull().mean() * 100\n",
    "perc_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df_accidents_1980.apply(lambda col: col.unique())\n",
    "df_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_index_unique_counts = len(\n",
    "    df_accidents_1980[\"accident_index\"].unique())\n",
    "accident_refernce_unique_counts = len(\n",
    "    df_accidents_1980[\"accident_reference\"].unique())\n",
    "number_of_entries = len(df_accidents_1980)\n",
    "\"Number of Unique accident_index: \" + \\\n",
    "    str(accident_index_unique_counts), \"Number of Unique accident_refrence: \" + \\\n",
    "    str(accident_refernce_unique_counts), \"Number of total entries:  \" + \\\n",
    "    str(number_of_entries)\n",
    "\n",
    "(np.equal((df_accidents_1980[\"accident_year\"].astype(str) +\n",
    "          df_accidents_1980[\"accident_reference\"]), df_accidents_1980[\"accident_index\"])).all()\n",
    "\n",
    "df_accidents_1980[\"accident_year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_c_un = df_accidents_1980[df_accidents_1980['first_road_class']\n",
    "                         == 'C']['first_road_class'].count() + df_accidents_1980[df_accidents_1980['first_road_class']\n",
    "                                                                                       == 'Unclassified']['first_road_class'].count()\n",
    "num_missing_road = df_accidents_1980[df_accidents_1980['first_road_number']\n",
    "                                     == 'first_road_class is C or Unclassified. These roads do not have official numbers so recorded as zero ']['first_road_class'].count()\n",
    "if num_c_un == num_missing_road:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accidents_1980_clean = df_accidents_1980.replace(\n",
    "    'Data missing or out of range', np.nan)\n",
    "df_accidents_1980_clean = df_accidents_1980_clean.replace(\n",
    "    -1, np.nan)\n",
    "df_accidents_1980_clean = df_accidents_1980_clean.replace(\n",
    "    '-1', np.nan)\n",
    "df_accidents_1980_clean = df_accidents_1980_clean.replace(\n",
    "    'first_road_class is C or Unclassified. These roads do not have official numbers so recorded as zero ', 0)\n",
    "df_null = df_accidents_1980_clean.isnull().mean() * 100\n",
    "df_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accidents_1980_clean = df_accidents_1980_clean.dropna(\n",
    "    axis='columns', how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.equal((df_accidents_1980[\"accident_year\"].astype(str) +\n",
    "          df_accidents_1980[\"accident_reference\"]), df_accidents_1980[\"accident_index\"])).all()  # checking the accident_year concatenated to the accident_reference is equal to the accident_index\n",
    "df_accidents_1980_clean = df_accidents_1980_clean.drop(\n",
    "    'accident_index', axis=1)  # dropping the accident_index\n",
    "\n",
    "df_accidents_1980_clean = df_accidents_1980_clean.set_index(\n",
    "    'accident_reference')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accidents_1980_clean = df_accidents_1980_clean.dropna(\n",
    "    axis='index', how='any', subset=['location_easting_osgr', 'location_easting_osgr', 'junction_detail', 'first_road_number', 'light_conditions', 'weather_conditions', 'road_surface_conditions', 'carriageway_hazards'])\n",
    "#df_accidents_1980_clean = df_accidents_1980_clean.drop('second_road_number',axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = df_accidents_1980_clean[(df_accidents_1980_clean['second_road_class'].notna()) & ~(\n",
    "    df_accidents_1980_clean['second_road_number'].notna())].index\n",
    "df_accidents_1980_clean = df_accidents_1980_clean.drop(df_filter)\n",
    "print((df_accidents_1980_clean[df_accidents_1980_clean['junction_detail']\n",
    "                         == 'Not at junction or within 20 metres']['junction_detail'].count()) / len(df_accidents_1980_clean.index) * 100)\n",
    "\n",
    "print(df_null['junction_control'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = df_accidents_1980_clean[((df_accidents_1980_clean['junction_detail'] != 'Not at junction or within 20 metres') & ~(\n",
    "    df_accidents_1980_clean['junction_control'].notna())) |((df_accidents_1980_clean['junction_detail'].isna()) & (\n",
    "    df_accidents_1980_clean['junction_control'].notna()))].index\n",
    "df_accidents_1980_clean = df_accidents_1980_clean.drop(df_filter)\n",
    "print((df_accidents_1980_clean[df_accidents_1980_clean['junction_detail']\n",
    "                         == 'Not at junction or within 20 metres']['junction_detail'].count()) / len(df_accidents_1980_clean.index) * 100)\n",
    "\n",
    "print(df_null['junction_control'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = df_accidents_1980_clean[['pedestrian_crossing_human_control',\n",
    "                                 'pedestrian_crossing_physical_facilities']].dropna()\n",
    "data['pedestrian_crossing_physical_facilities'] = data['pedestrian_crossing_physical_facilities'].astype(\n",
    "    'category')\n",
    "data['pedestrian_crossing_physical_facilities'] = data['pedestrian_crossing_physical_facilities'].cat.codes\n",
    "\n",
    "data['pedestrian_crossing_human_control'] = data['pedestrian_crossing_human_control'].astype(\n",
    "    'category')\n",
    "data['pedestrian_crossing_human_control'] = data['pedestrian_crossing_human_control'].cat.codes\n",
    "\n",
    "sns.kdeplot(data[\"pedestrian_crossing_physical_facilities\"])\n",
    "\n",
    "plt.show()\n",
    "sns.kdeplot(data[\"pedestrian_crossing_human_control\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"pedestrian_crossing_human_control\"].median()\n",
    "ind = data[data[\"pedestrian_crossing_human_control\"] == data[\"pedestrian_crossing_human_control\"].median()].index[0]\n",
    "pedesMedian = df_accidents_1980_clean[\"pedestrian_crossing_human_control\"][ind]\n",
    "df_accidents_1980_clean[\"pedestrian_crossing_human_control\"] = df_accidents_1980_clean[\"pedestrian_crossing_human_control\"].replace(np.nan, pedesMedian)\n",
    "df_null = df_accidents_1980_clean.isna().mean() * 100\n",
    "\n",
    "df_null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"pedestrian_crossing_physical_facilities\"].median()\n",
    "ind = data[data[\"pedestrian_crossing_physical_facilities\"] == data[\"pedestrian_crossing_physical_facilities\"].median()].index[0]\n",
    "pedesMedian = df_accidents_1980_clean[\"pedestrian_crossing_physical_facilities\"][ind]\n",
    "df_accidents_1980_clean[\"pedestrian_crossing_physical_facilities\"] = df_accidents_1980_clean[\"pedestrian_crossing_physical_facilities\"].replace(np.nan, pedesMedian)\n",
    "df_null = df_accidents_1980_clean.isna().mean() * 100\n",
    "\n",
    "df_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accidents_1980_clean[\"special_conditions_at_site\"].unique()\n",
    "data = df_accidents_1980_clean[['special_conditions_at_site']].dropna()\n",
    "data['special_conditions_at_site'] = data['special_conditions_at_site'].astype(\n",
    "    'category')\n",
    "data['special_conditions_at_site'] = data['special_conditions_at_site'].cat.codes\n",
    "sns.kdeplot(data[\"special_conditions_at_site\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"special_conditions_at_site\"].median()\n",
    "ind = data[data[\"special_conditions_at_site\"] == data[\"special_conditions_at_site\"].median()].index[0]\n",
    "specMedian = df_accidents_1980_clean[\"special_conditions_at_site\"][ind]\n",
    "df_accidents_1980_clean[\"special_conditions_at_site\"] = df_accidents_1980_clean[\"special_conditions_at_site\"].replace(np.nan, pedesMedian)\n",
    "df_null = df_accidents_1980_clean.isna().mean() * 100\n",
    "\n",
    "df_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings and conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = df_accidents_1980_clean[['road_type']].dropna()\n",
    "data['road_type'] = data['road_type'].astype(\n",
    "    'category')\n",
    "data['road_type'] = data['road_type'].cat.codes\n",
    "sns.kdeplot(data[\"road_type\"])\n",
    "data[\"road_type\"].median()\n",
    "ind = data[data[\"road_type\"] == data[\"road_type\"].median()].index[0]\n",
    "specMedian = df_accidents_1980_clean[\"road_type\"][ind]\n",
    "df_accidents_1980_clean[\"road_type\"] = df_accidents_1980_clean[\"road_type\"].replace(np.nan, pedesMedian)\n",
    "df_accidents_1980_clean[\"junction_control\"] = df_accidents_1980_clean[\"junction_control\"].replace(np.nan, \"Non\")\n",
    "\n",
    "df_accidents_1980_clean = df_accidents_1980_clean.drop('second_road_class',axis=1)\n",
    "df_accidents_1980_clean = df_accidents_1980_clean.drop('second_road_number',axis=1)\n",
    "df_null = df_accidents_1980_clean.isna().mean() * 100\n",
    "\n",
    "df_null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df_accidents_1980_clean['number_of_vehicles'])\n",
    "\n",
    "z = np.abs(stats.zscore(df_accidents_1980_clean['number_of_vehicles']))\n",
    "\n",
    "veh_filtered_entries = z < 3\n",
    "(np.bitwise_not(veh_filtered_entries).sum() /\n",
    " len(df_accidents_1980_clean.index)) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(df_accidents_1980_clean['number_of_vehicles'])\n",
    "Q1 = df_accidents_1980_clean['number_of_vehicles'].quantile(0.25)\n",
    "Q3 = df_accidents_1980_clean['number_of_vehicles'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)\n",
    "cut_off = IQR * 1.5\n",
    "lower = Q1 - cut_off\n",
    "upper = Q3 + cut_off\n",
    "print(lower, upper)\n",
    "df1 = df_accidents_1980_clean[df_accidents_1980_clean['number_of_vehicles'] > upper]\n",
    "df2 = df_accidents_1980_clean[df_accidents_1980_clean['number_of_vehicles'] < lower]\n",
    "print('Percentage of outliers are',\n",
    "      (df1.shape[0] + df2.shape[0]) / len(df_accidents_1980_clean.index) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df_accidents_1980_clean['number_of_casualties'])\n",
    "\n",
    "z = np.abs(stats.zscore(df_accidents_1980_clean['number_of_casualties']))\n",
    "\n",
    "cas_filtered_entries = z < 4\n",
    "(np.bitwise_not(cas_filtered_entries).sum() /\n",
    " len(df_accidents_1980_clean.index)) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(df_accidents_1980_clean['number_of_casualties'])\n",
    "Q1 = df_accidents_1980_clean['number_of_casualties'].quantile(0.25)\n",
    "Q3 = df_accidents_1980_clean['number_of_casualties'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)\n",
    "cut_off = IQR * 1.5\n",
    "lower = Q1 - cut_off\n",
    "upper = Q3 + cut_off\n",
    "print(lower, upper)\n",
    "df1 = df_accidents_1980_clean[df_accidents_1980_clean['number_of_casualties'] > upper]\n",
    "df2 = df_accidents_1980_clean[df_accidents_1980_clean['number_of_casualties'] < lower]\n",
    "print('Percentage of outliers are',\n",
    "      (df1.shape[0] + df2.shape[0]) / len(df_accidents_1980_clean.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df_accidents_1980_clean['speed_limit'])\n",
    "\n",
    "z = np.abs(stats.zscore(df_accidents_1980_clean['speed_limit']))\n",
    "\n",
    "filtered_entries = z < 3\n",
    "(np.bitwise_not(filtered_entries).sum() / len(df_accidents_1980_clean.index)) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(df_accidents_1980_clean['speed_limit'])\n",
    "Q1 = df_accidents_1980_clean['speed_limit'].quantile(0.25)\n",
    "Q3 = df_accidents_1980_clean['speed_limit'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)\n",
    "cut_off = IQR * 1.5\n",
    "lower = Q1 - cut_off\n",
    "upper = Q3 + cut_off\n",
    "print(lower, upper)\n",
    "df1 = df_accidents_1980_clean[df_accidents_1980_clean['speed_limit'] > upper]\n",
    "df2 = df_accidents_1980_clean[df_accidents_1980_clean['speed_limit'] < lower]\n",
    "print('Percentage of outliers are',\n",
    "      (df1.shape[0] + df2.shape[0]) / len(df_accidents_1980_clean.index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veh_med = df_accidents_1980_clean[veh_filtered_entries]['number_of_vehicles'].median(\n",
    ")\n",
    "print(veh_med)\n",
    "print(len(df_accidents_1980_clean.index))\n",
    "df_accidents_1980_clean['number_of_vehicles'] = df_accidents_1980_clean['number_of_vehicles'].where(\n",
    "    veh_filtered_entries, other=veh_med)\n",
    "df_accidents_1980_clean[~veh_filtered_entries]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cas_med = df_accidents_1980_clean[cas_filtered_entries]['number_of_casualties'].median(\n",
    ")\n",
    "print(cas_filtered_entries)\n",
    "print(len(df_accidents_1980_clean.index))\n",
    "df_accidents_1980_clean['number_of_casualties'] = df_accidents_1980_clean['number_of_casualties'].where(\n",
    "    cas_filtered_entries, other=cas_med)\n",
    "df_accidents_1980_clean[~cas_filtered_entries]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings and conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 - Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.11 - Findings and conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 - Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.22 - Findings and conlcusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 - Normalisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.31 - Findings and conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 - Adding more columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.41 - Findings and concluisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 - Csv file for lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Exporting the dataframe to a csv file or parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
